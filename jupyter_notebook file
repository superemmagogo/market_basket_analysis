Association Rules: 

Support

Support is an indication of how frequently the item set appears in the data set.
In other words, it's the number of transactions with both X and Y divided by the total number of transactions. The rules are not useful for low support values. 
# 既有X又有Y/所有   --> X和Y同时发生的概率  --> support is the probability 

Confidence

For a rule X --> Y, confidence shows the percentage in which Y is bought with X. It's an indication of how often the rule has been found to be true.
# 既有X又有Y/X  --> X和Y同时发生的次数/X发生的次数 --> P(Y|X) 条件概率 conditional probability 


Lift

The lift of a rule is the ratio of the observed support to that expected if X and Y were independent, and is defined as
# X和Y同时发生的概率/（X发生的概率*Y发生的概率） 
Greater lift values indicate stronger associations. 

Lift (A => B) = 1 means that there is no correlation within the itemset.
Lift (A => B) > 1 means that there is a positive correlation within the itemset, i.e., products in the itemset, A, and B, are more likely to be bought together.
Lift (A => B) < 1 means that there is a negative correlation within the itemset, i.e., products in itemset, A, and B, are unlikely to be bought together.


Conviction

The conviction of a rule is defined as 

conv(X --> Y)= (1-P(Y))/ (1-P(Y|X)

It can be interpreted as the ratio of the expected frequency that $X$ occurs without $Y$ if $X$  and $Y$ were independent divided by the observed frequency of incorrect predictions. 
A high value means that the consequent depends strongly on the antecedent. Let's see some examples: 

Association Rule-based algorithms are viewed as a two-step approach:
Frequent Itemset Generation: 
Find all frequent item-sets with support >= pre-determined min_support count
Rule Generation: 
List all Association Rules from frequent item-sets. Calculate Support and Confidence for all rules. Prune rules that fail min_support and min_confidence thresholds.

Limitation of Apriori algorithm
Frequent Itemset Generation is the most computationally expensive step because the algorithm scans the database too many times, which reduces the overall performance. 
Due to this, the algorithm assumes that the database is Permanent in the memory.
Also, both the time and space complexity of this algorithm are very high: O(2^{|D|}), thus exponential, where |D| is the horizontal width (the total number of items) present in the database.
